{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data\n",
    "### Data: \n",
    "- [Reuters-21578 Text Categorization Collection Data Set] from UCI Machine Learning Repository\n",
    "- It contains 21,578 news articles from Reuters in 1987\n",
    "- Available at: https://archive.ics.uci.edu/ml/datasets/reuters-21578+text+categorization+collection \n",
    "\n",
    "### Format:\n",
    "- News: 21 SGML files\n",
    "    - We only deal with news contents inside <body> </body> tags\n",
    "- The other files will not be needed in this homework\n",
    "\n",
    "\n",
    "1. <b>Shingling</b>: Converts a document into a set representation (Boolean vector)\n",
    "\n",
    "2. <b>Min-Hashing</b>: Convert large sets to short signatures, while preserving similarity\n",
    "\n",
    "3. <b>Locality-Sensitive Hashing</b>: Focus on pairs of signatures likely to be from similar documents. Candidate pairs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering sgm files using python library sgmllib for parsing process make to to documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mall-exchanges-strings.lc.txt\u001b[0m*        \u001b[01;32mreut2-002.sgm\u001b[0m*  \u001b[01;32mreut2-013.sgm\u001b[0m*\r\n",
      "\u001b[01;32mall-orgs-strings.lc.txt\u001b[0m*             \u001b[01;32mreut2-003.sgm\u001b[0m*  \u001b[01;32mreut2-014.sgm\u001b[0m*\r\n",
      "\u001b[01;32mall-people-strings.lc.txt\u001b[0m*           \u001b[01;32mreut2-004.sgm\u001b[0m*  \u001b[01;32mreut2-015.sgm\u001b[0m*\r\n",
      "\u001b[01;32mall-places-strings.lc.txt\u001b[0m*           \u001b[01;32mreut2-005.sgm\u001b[0m*  \u001b[01;32mreut2-016.sgm\u001b[0m*\r\n",
      "\u001b[01;32mall-topics-strings.lc.txt\u001b[0m*           \u001b[01;32mreut2-006.sgm\u001b[0m*  \u001b[01;32mreut2-017.sgm\u001b[0m*\r\n",
      "\u001b[01;32mcat-descriptions_120396.txt\u001b[0m*         \u001b[01;32mreut2-007.sgm\u001b[0m*  \u001b[01;32mreut2-018.sgm\u001b[0m*\r\n",
      "\u001b[01;32mfeldman-cia-worldfactbook-data.txt\u001b[0m*  \u001b[01;32mreut2-008.sgm\u001b[0m*  \u001b[01;32mreut2-019.sgm\u001b[0m*\r\n",
      "\u001b[01;32mlewis.dtd\u001b[0m*                           \u001b[01;32mreut2-009.sgm\u001b[0m*  \u001b[01;32mreut2-020.sgm\u001b[0m*\r\n",
      "\u001b[01;32mREADME.txt\u001b[0m*                          \u001b[01;32mreut2-010.sgm\u001b[0m*  \u001b[01;32mreut2-021.sgm\u001b[0m*\r\n",
      "\u001b[01;32mreut2-000.sgm\u001b[0m*                       \u001b[01;32mreut2-011.sgm\u001b[0m*\r\n",
      "\u001b[01;32mreut2-001.sgm\u001b[0m*                       \u001b[01;32mreut2-012.sgm\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "#list of dataset in my directory\n",
    "data_path = \"/home/twster/Spark/Projects/datasets/reuters21578\"\n",
    "%ls $data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing sgml files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function for parsing sgml files using sgmllib python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sgmllib\n",
    "import fnmatch\n",
    "import os\n",
    "import re\n",
    "import binascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _not_in_sphinx():\n",
    "    \n",
    "    return '__file__' in globals()\n",
    "class ReutersParser(sgmllib.SGMLParser):\n",
    "\n",
    "    \"\"\"Utility class to parse a SGML file and yield documents one at a time.\"\"\"\n",
    "\n",
    "    def __init__(self, verbose=0):\n",
    "        sgmllib.SGMLParser.__init__(self, verbose)\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self):\n",
    "        self.in_title = 0\n",
    "        self.in_body = 0\n",
    "        self.in_topics = 0\n",
    "        self.in_topic_d = 0\n",
    "        self.title = \"\"\n",
    "        self.body = \"\"\n",
    "        self.topics = []\n",
    "        self.topic_d = \"\"\n",
    "\n",
    "    def parse(self, fd):\n",
    "        self.docs = []\n",
    "        for chunk in fd:\n",
    "            self.feed(chunk)\n",
    "            for doc in self.docs:\n",
    "                yield doc\n",
    "            self.docs = []\n",
    "        self.close()\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        if self.in_body:\n",
    "            self.body += data\n",
    "        elif self.in_title:\n",
    "            self.title += data\n",
    "        elif self.in_topic_d:\n",
    "            self.topic_d += data\n",
    "\n",
    "    def start_reuters(self, attributes):\n",
    "        pass\n",
    "\n",
    "    def end_reuters(self):\n",
    "        self.body = re.sub(r'\\s+', r' ', self.body)\n",
    "        self.docs.append({'title': self.title,\n",
    "                          'body': self.body,\n",
    "                          'topics': self.topics})\n",
    "        self._reset()\n",
    "\n",
    "    def start_title(self, attributes):\n",
    "        self.in_title = 1\n",
    "\n",
    "    def end_title(self):\n",
    "        self.in_title = 0\n",
    "\n",
    "    def start_body(self, attributes):\n",
    "        self.in_body = 1\n",
    "\n",
    "    def end_body(self):\n",
    "        self.in_body = 0\n",
    "\n",
    "    def start_topics(self, attributes):\n",
    "        self.in_topics = 1\n",
    "\n",
    "    def end_topics(self):\n",
    "        self.in_topics = 0\n",
    "\n",
    "    def start_d(self, attributes):\n",
    "        self.in_topic_d = 1\n",
    "\n",
    "    def end_d(self):\n",
    "        self.in_topic_d = 0\n",
    "        self.topics.append(self.topic_d)\n",
    "        self.topic_d = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReutersStreamReader():\n",
    "    def iterdocs(self):\n",
    "        \"\"\"Iterate doc by doc, yield a dict.\"\"\"\n",
    "        for root, _dirnames, filenames in os.walk(data_path):\n",
    "            for filename in fnmatch.filter(filenames, '*.sgm'):\n",
    "                path = os.path.join(root, filename)\n",
    "                parser = ReutersParser()\n",
    "                for doc in parser.parse(open(path)):\n",
    "                    yield doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "call function iterdoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_streamer = ReutersStreamReader().iterdocs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyspark libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://sparklab-master:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://sparklab-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://sparklab-master:7077 appName=PySparkShell>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = SparkConf().setMaster(\"spark://sparklab-master:7077\").setAppName(\"HW#3\")\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "sqlContext=SQLContext(sc)\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make parallelize from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize(data_streamer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show dataset : 'title', 'topics', 'body'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'body': 'Media group John Fairfax Ltd <FFXA.S> said that its flat first half net profit partly reflected the impact of changes in the Australian tax system. Fairfax earlier reported net earnings edged up 2.3 pct to 25.94 mln dlrs in the 26 weeks ended December 28 from 25.35 mln a year earlier although pre-tax profit rose 9.1 pct to 48.30 mln from 44.29 mln. Net would have risen 10.1 pct but for the increase in company tax to 49 pct from 46 and the imposition of the tax on fringe benefits, paid by employers and not the recipients, the company said in a statement. Fairfax also pointed to the cyclical downturn in revenue growth in the television industry as another reason for the flat first half earnings. It said it considered the result satisfactory in view of these factors. Fairfax said its flagship dailies, The Sydney Morning Herald and the Melbourne Age, boosted advertising volume, as did the Australian Financial Review, and posted extremely satisfactory performances. Magazines also performed strongly. But an 8.9 pct rise in television costs outweighed a 4.0 pct rise in revenue, it said. Fairfax said a fall in net interest also contributed to net earnings because group borrowings were reduced following the receipt of a 96.11 mln dlr capital dividend from <Australian Associated Press Pty Ltd> (AAP) after the sale of AAP\\'s \"B\" shares in Reuters Holdings Plc <RTRS.L>. This accounted for the 89.32 mln dlr extraordinary profit. Fairfax said it is too early to predict results for the full year. Increased borrowings after the recent 320 mln dlr acquisition of the HSV-Seven television station in Melbourne will hit earnings but networking with the Channel Sevens in Sydney and Brisbane will produce some offsetting cost savings. REUTER \\x03',\n",
       "  'title': 'FAIRFAX SAYS HIGHER TAX HITS FIRST HALF EARNINGS',\n",
       "  'topics': ['earn', 'australia']},\n",
       " {'body': 'The Bank of France sold 1.6 billion francs of 8.50 pct March 1987/99 Caisse de Refinancement Hypothecaire (CRH) state-guaranteed tap stock at an auction, the Bank said. Demand totalled 6.82 billion francs and prices bid ranged from 93.50 to 96.60 pct. The minimum accepted price was 95.50 pct with a 9.13 pct yield, while the average price was 95.69. At the last auction on February 19, two billion francs of CRH tap stock was sold at a minimum price of 91.50 pct and yield of 9.73 pct. REUTER \\x03',\n",
       "  'title': 'BANK OF FRANCE SELLS 1.6 BILLION FRANCS CRH TAP',\n",
       "  'topics': ['france']},\n",
       " {'body': \"Shr 6.56p vs 50.31p Final div 6p, making 8p vs 13p. Pre-tax profit 134 mln stg vs 759 mln. Net profit 33 mln vs 253 mln. Turnover 978 mln stg vs 1.80 billion. Extraordinary debit 50 mln vs nil. Operating profit 149 mln stg vs 756 mln. Exceptional debit on rationalisation programme 12 mln vs nil Petroleum Revenue Taxes 77 mln vs 319 mln, U.K. Corporation tax and overseas tax 24 mln vs 187 mln, Note - The net effect of accounting changes in 1986 was to reduce after tax profits by 47 mln stg. Retained earnings for prior years were increased by 209 mln. Extraordinary debit of 50 mln stg related to the decision to seek a buyer for the company's U.S. Assets. REUTER \\x03\",\n",
       "  'title': 'BRITOIL PLC <BTOL.L> 1986 YR',\n",
       "  'topics': ['earn', 'uk']},\n",
       " {'body': '', 'title': '', 'topics': ['jobs', 'uk']},\n",
       " {'body': '',\n",
       "  'title': 'UK UNIT WAGE/LABOUR COSTS ROSE 3.3 PCT IN THREE MONTHS ENDING JAN - OFFICIAL\\n',\n",
       "  'topics': ['income', 'uk']},\n",
       " {'body': '',\n",
       "  'title': 'UK AVERAGE EARNINGS ROSE 7.6 PCT IN JANUARY, UNDERLYING RISE 7.5 PCT - OFFICIAL\\n',\n",
       "  'topics': ['income', 'uk']},\n",
       " {'body': '',\n",
       "  'title': 'U.K. FEBRUARY ADJUSTED STERLING M3 RISES 2-1/4 PCT, M0 DOWN 3/4 TO ONE PCT - OFFICIAL\\n',\n",
       "  'topics': ['money-supply', 'uk']},\n",
       " {'body': 'Shr 14.58p vs 7.86p Div 6.5p making 9.75p, an increase of 19.4 pct Pretax profit 83.2 mln stg vs 31.5 mln Net after tax 68.6 mln stg vs 37.7 mln Pretax profit 83.2 mln stg vs 31.5 mln, consists of - Long term business 45.9 mln stg vs 43.8 mln U.S. Long term business 6.2 mln vs 8.9 mln Fund management 4.7 mln vs 6.5 mln Short term business 4.7 mln vs loss 29.0 mln Associate companies 0.9 mln vs 0.8 mln Shareholders other income and outgoings 0.4 mln debit vs 0.5 mln credit Exceptional long-term business profit 21.4 mln vs nil REUTER \\x03',\n",
       "  'title': 'LEGAL AND GENERAL GROUP PLC YEAR 1986',\n",
       "  'topics': ['earn', 'uk']},\n",
       " {'body': '',\n",
       "  'title': 'FEB STERLING BANK LENDING UP 2.9 BILLION STG AFTER 1.75 RISE IN JAN - OFFICIAL\\n',\n",
       "  'topics': ['money-supply']},\n",
       " {'body': '',\n",
       "  'title': 'UK FEB ADJUSTED UNEMPLOYMENT FELL 44,100 TOTAL 3.07 MLN OR 11.1 PCT - OFFICIAL\\n',\n",
       "  'topics': ['jobs', 'uk']}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "taking body files from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RDD from reuters dataset\n",
    "DataBody = data.map(lambda x: (x['body']).replace(\"\\x03\",\"\"))\n",
    "#Dataframe from reuters dataset\n",
    "df = DataBody.map(lambda x: (x,)).toDF().withColumnRenamed(\"_1\", \"reuters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21578"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(DataBody.collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Given the Reuters-21578 dataset, please calculate all k-shingles and output the set representation of the text dataset as a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getShingles(line):\n",
    "    k=5\n",
    "    BodyText = ' '.join([line[:-1].strip()])\n",
    "    BodyText = re.sub(' +', ' ', BodyText)  # remove double spaces\n",
    "    # get all k-shingles and return their hash codes\n",
    "    shingles = set()\n",
    "    L = len(BodyText)\n",
    "    for i in xrange(L-k+1):\n",
    "        shingle = BodyText[i:i+k]\n",
    "        crc = binascii.crc32(shingle) & 0xffffffff  #hash the shingle to a 32-bit integer\n",
    "        shingles.add(crc)\n",
    "    return shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shinglesBodyRDD = DataBody.map(getShingles)\n",
    "#Save output to TextFiles\n",
    "shinglesBodyRDD.saveAsTextFile(\"output/HW#4/Q1/KShinglesBodyText\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Given the set representation, compute the minhash signatures of all documents using MapReduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, CountVectorizer\n",
    "\n",
    "#Tokenizer\n",
    "tokens = Tokenizer(inputCol=\"reuters\", outputCol=\"flat_output\")\n",
    "dfWithTokenizer = tokens.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CountVectorizer\n",
    "dfCV = CountVectorizer(inputCol=\"flat_output\",outputCol=\"features\")\n",
    "model = dfCV.fit(dfWithTokenizer)\n",
    "dfCVector = model.transform(dfWithTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|             reuters|         flat_output|            features|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|Media group John ...|[media, group, jo...|(104121,[0,1,2,3,...|\n",
      "|The Bank of Franc...|[the, bank, of, f...|(104121,[0,1,2,3,...|\n",
      "|Shr 6.56p vs 50.3...|[shr, 6.56p, vs, ...|(104121,[0,1,2,3,...|\n",
      "|                    |                  []| (104121,[96],[1.0])|\n",
      "|                    |                  []| (104121,[96],[1.0])|\n",
      "|                    |                  []| (104121,[96],[1.0])|\n",
      "|                    |                  []| (104121,[96],[1.0])|\n",
      "|Shr 14.58p vs 7.8...|[shr, 14.58p, vs,...|(104121,[1,3,8,10...|\n",
      "|                    |                  []| (104121,[96],[1.0])|\n",
      "|                    |                  []| (104121,[96],[1.0])|\n",
      "|The Ministry of I...|[the, ministry, o...|(104121,[0,1,2,3,...|\n",
      "|Clearing bank ste...|[clearing, bank, ...|(104121,[0,1,2,3,...|\n",
      "|Unemployment in t...|[unemployment, in...|(104121,[0,1,2,3,...|\n",
      "|The main measure ...|[the, main, measu...|(104121,[0,1,2,3,...|\n",
      "|U.K. Average earn...|[u.k., average, e...|(104121,[0,1,2,3,...|\n",
      "|U.K. Property com...|[u.k., property, ...|(104121,[0,1,3,4,...|\n",
      "|Nomura Internatio...|[nomura, internat...|(104121,[0,1,3,4,...|\n",
      "|AB Volvo is issui...|[ab, volvo, is, i...|(104121,[0,1,3,4,...|\n",
      "|Finance Minister ...|[finance, ministe...|(104121,[0,1,2,3,...|\n",
      "|The Bank of Engla...|[the, bank, of, e...|(104121,[0,1,2,4,...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import MinHashLSH\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "#feature Transformation\n",
    "mh = MinHashLSH(inputCol=\"features\", outputCol=\"hashes\", numHashTables=5)\n",
    "model = mh.fit(dfCVector)\n",
    "dfCVector.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|             reuters|         flat_output|            features|              hashes|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|Media group John ...|[media, group, jo...|(104121,[0,1,2,3,...|[[-2.025105913E9]...|\n",
      "|The Bank of Franc...|[the, bank, of, f...|(104121,[0,1,2,3,...|[[-2.016181972E9]...|\n",
      "|Shr 6.56p vs 50.3...|[shr, 6.56p, vs, ...|(104121,[0,1,2,3,...|[[-2.024735297E9]...|\n",
      "|                    |                  []| (104121,[96],[1.0])|[[-3.52343011E8],...|\n",
      "|                    |                  []| (104121,[96],[1.0])|[[-3.52343011E8],...|\n",
      "|                    |                  []| (104121,[96],[1.0])|[[-3.52343011E8],...|\n",
      "|                    |                  []| (104121,[96],[1.0])|[[-3.52343011E8],...|\n",
      "|Shr 14.58p vs 7.8...|[shr, 14.58p, vs,...|(104121,[1,3,8,10...|[[-1.982054458E9]...|\n",
      "|                    |                  []| (104121,[96],[1.0])|[[-3.52343011E8],...|\n",
      "|                    |                  []| (104121,[96],[1.0])|[[-3.52343011E8],...|\n",
      "|The Ministry of I...|[the, ministry, o...|(104121,[0,1,2,3,...|[[-2.024735297E9]...|\n",
      "|Clearing bank ste...|[clearing, bank, ...|(104121,[0,1,2,3,...|[[-2.034029854E9]...|\n",
      "|Unemployment in t...|[unemployment, in...|(104121,[0,1,2,3,...|[[-2.034029854E9]...|\n",
      "|The main measure ...|[the, main, measu...|(104121,[0,1,2,3,...|[[-2.028527243E9]...|\n",
      "|U.K. Average earn...|[u.k., average, e...|(104121,[0,1,2,3,...|[[-2.028527243E9]...|\n",
      "|U.K. Property com...|[u.k., property, ...|(104121,[0,1,3,4,...|[[-1.886286375E9]...|\n",
      "|Nomura Internatio...|[nomura, internat...|(104121,[0,1,3,4,...|[[-1.994770345E9]...|\n",
      "|AB Volvo is issui...|[ab, volvo, is, i...|(104121,[0,1,3,4,...|[[-1.886286375E9]...|\n",
      "|Finance Minister ...|[finance, ministe...|(104121,[0,1,2,3,...|[[-1.985475788E9]...|\n",
      "|The Bank of Engla...|[the, bank, of, e...|(104121,[0,1,2,4,...|[[-2.006146183E9]...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MinHashSignatures = model.transform(dfCVector)\n",
    "MinHashSignatures.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinHashSignatures.select(\"hashes\").rdd.flatMap(lambda x: x['hashes']).saveAsTextFile(\"output/HW#4/Q2/Text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Implement the LSH algorithm by MapReduce and output the resulting candidate pairs of similar documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+\n",
      "|            ReutersA|            ReutersB|    JaccardDistance|\n",
      "+--------------------+--------------------+-------------------+\n",
      "|[Shr six cts vs s...|[Qtly div 47-1/2 ...| 0.5555555555555556|\n",
      "|[3250 tonnes main...|[2650 tonnes main...| 0.5454545454545454|\n",
      "|[The Bank of Engl...|[The Bank of Engl...| 0.5151515151515151|\n",
      "|[Shr profit three...|[Shr 11 cts vs th...| 0.5263157894736843|\n",
      "|[Qtly div 11 cts ...|[Qtly div nine ct...|0.47058823529411764|\n",
      "|[Zayre Corp said ...|[Best Products Co...| 0.5853658536585367|\n",
      "|[Shr 32 cts vs 32...|[Shr 25 cts vs 25...|0.47058823529411764|\n",
      "|[DIst nine cts vs...|[Qtly div three c...| 0.5882352941176471|\n",
      "|[Qtly div 10 cts ...|[Qtly div 15 cts ...| 0.4117647058823529|\n",
      "|[Qtly div 10 cts ...|[Qtly div 15 cts ...|                0.4|\n",
      "|[Qtly div 10 cts ...|[Qtly div 18 cts ...|             0.4375|\n",
      "|[Qtly div 10 cts ...|[Qtly div 41.5 ct...|             0.4375|\n",
      "|[Qtly div 10 cts ...|[Qtly div eight c...|                0.4|\n",
      "|[Qtly div 10 cts ...|[Qtly div 1-3/4 c...|0.33333333333333337|\n",
      "|[Qtly div 10 cts ...|[Qtly div 12-1/2 ...|0.33333333333333337|\n",
      "|[Qtly div 11 cts ...|[Qtly div eight c...| 0.2142857142857143|\n",
      "|[Qtly div 11 cts ...|[Qtly div six cts...|                0.5|\n",
      "|[Qtly div 12 cts ...|[Qtly div 45 cts ...|             0.4375|\n",
      "|[Qtly div 12 cts ...|[Qtly div 12-1/2 ...|              0.375|\n",
      "|[Qtly div 12 cts ...|[Qtly div 20 cts ...|0.33333333333333337|\n",
      "+--------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.approxSimilarityJoin(dfCVector, dfCVector, 0.6, distCol=\"JaccardDistance\").filter(\"JaccardDistance != 0\").\\\n",
    "    select(col(\"datasetA\").alias(\"ReutersA\"),\n",
    "           col(\"datasetB\").alias(\"ReutersB\"),\n",
    "           col(\"JaccardDistance\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Implement K-nearest neighbor (KNN) search using LSH and compare its performance with linear search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximately searching dfCVector for 100 nearest neighbors of the key:\n",
      "+--------------------+--------------------+--------------------+--------------------+------------------+\n",
      "|             reuters|         flat_output|            features|              hashes|           distCol|\n",
      "+--------------------+--------------------+--------------------+--------------------+------------------+\n",
      "|Thera-Care Inc sa...|[thera-care, inc,...|(104121,[1,2,3,4,...|[[-1.691699495E9]...|0.8947368421052632|\n",
      "|National Distille...|[national, distil...|(104121,[1,2,3,6,...|[[-1.893870267E9]...|               0.9|\n",
      "|Key Centurion Ban...|[key, centurion, ...|(104121,[0,1,3,6,...|[[-1.933129776E9]...|               0.9|\n",
      "|Dataproducts Corp...|[dataproducts, co...|(104121,[1,2,3,6,...|[[-1.253971669E9]...|               0.9|\n",
      "|Alcide Corp said ...|[alcide, corp, sa...|(104121,[0,1,3,6,...|[[-1.358720322E9]...|0.9047619047619048|\n",
      "|<TelWatch Inc> sa...|[<telwatch, inc>,...|(104121,[1,3,6,9,...|[[-1.673110381E9]...|0.9047619047619048|\n",
      "|Grumman Corp said...|[grumman, corp, s...|(104121,[0,1,3,6,...|[[-1.764715902E9]...|0.9047619047619048|\n",
      "|Qtly div four cts...|[qtly, div, four,...|(104121,[1,3,10,2...|[[-2.007856848E9]...|0.9047619047619048|\n",
      "|<Willemijn Holdin...|[<willemijn, hold...|(104121,[1,2,3,6,...|[[-1.960785246E9]...|0.9090909090909091|\n",
      "|LADD Furniture In...|[ladd, furniture,...|(104121,[0,1,3,6,...|[[-1.600093974E9]...|0.9090909090909091|\n",
      "|Ameribanc Investo...|[ameribanc, inves...|(104121,[0,1,3,10...|[[-1.95171889E9],...|0.9090909090909091|\n",
      "|Bank of New Engla...|[bank, of, new, e...|(104121,[1,2,3,6,...|[[-1.669289278E9]...|0.9090909090909091|\n",
      "|Dynalectron Corp ...|[dynalectron, cor...|(104121,[1,3,4,6,...|[[-1.691699495E9]...|0.9090909090909091|\n",
      "|RTE Corp said it ...|[rte, corp, said,...|(104121,[0,1,3,6,...|[[-1.51778301E9],...|0.9090909090909091|\n",
      "|Bowne and Co Inc ...|[bowne, and, co, ...|(104121,[1,2,3,5,...|[[-2.007856848E9]...|0.9090909090909091|\n",
      "|Mellon Bank NA of...|[mellon, bank, na...|(104121,[1,2,3,10...|[[-2.01387249E9],...|0.9130434782608696|\n",
      "|CB and T Bancshar...|[cb, and, t, banc...|(104121,[0,1,3,6,...|[[-2.034029854E9]...|0.9130434782608696|\n",
      "|First Union Corp ...|[first, union, co...|(104121,[0,1,3,4,...|[[-1.989267734E9]...|0.9130434782608696|\n",
      "|Qtrly seven cts v...|[qtrly, seven, ct...|(104121,[1,3,10,1...|[[-2.007856848E9]...|0.9130434782608696|\n",
      "|To-Fitness Inc sa...|[to-fitness, inc,...|(104121,[0,1,3,6,...|[[-1.740766592E9]...|0.9130434782608696|\n",
      "+--------------------+--------------------+--------------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Approximately searching dfCVector for 100 nearest neighbors of the key:\")\n",
    "vocabSize = 104121\n",
    "key = Vectors.sparse(vocabSize, [1, 3], [1.0, 1.0])\n",
    "model.approxNearestNeighbors(dfCVector, key, 100).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.approxNearestNeighbors(dfCVector, key, 100).select(\"reuters\",\"distCol\").coalesce(1).write.format(\"csv\").options(header=\"true\").save(\"output/HW#4/Q4/\"+\"KNN\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
