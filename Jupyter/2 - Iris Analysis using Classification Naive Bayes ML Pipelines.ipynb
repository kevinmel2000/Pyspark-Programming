{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark - Classification - Naive Bayes Classifier ML Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Summary\n",
    "- Task : Classification with binary or multiclass labels\n",
    "- Input : Label (binary or multiclass, 0-based indexed), feature vectors(discrete)\n",
    "- Smoothing : Additive smothing, default parameter is set to 1.0\n",
    "- Model type : Multinomial (default) or Bernouli. to use Bernouli, convert feature vectors to 0-1 vectors and set modelType to \"Bernouli\"\n",
    "- Assumptions:\n",
    "    - Independence between every pair of features\n",
    "    - Feature values are nonnegative, such as counts\n",
    "\n",
    "\n",
    "## Data Analysis Example\n",
    "- <a href=\"https://github.com/vincentarelbundock/Rdatasets/blob/master/csv/datasets/iris.csv\">Iris dataset</a>\n",
    "- Make a connection to spark cluster\n",
    "- Dataset Review\n",
    "- Load Data & Data preprocessing\n",
    "- Explore the data\n",
    "- Create a multiclass naive Bayes Classifier and Evaluation\n",
    "- Experimenting with Various Smoothing Parameters\n",
    "\n",
    "## Dataset Review\n",
    "The dataset contains 3 species of iris, there are Setosa, Versicolor and Virginica with 50 instances of each. in this example, we are going to try to predict the species from its features.\n",
    "\n",
    "Feature Information:\n",
    "1. Sepal Length in cm\n",
    "2. Sepal Width in cm\n",
    "3. Petal Length in cm\n",
    "4. Petal Width in cm\n",
    "\n",
    "Target and Label :\n",
    "- Species\n",
    "    - Setosa\n",
    "    - Versicolor\n",
    "    - Virginica\n",
    "    \n",
    "## References :\n",
    "<a href=\"https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/3741049972324885/3783546674231736/4413065072037724/latest.html\">Naive Bayes Classifier - ML Pipelines</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import libraries from python\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get some context.\n",
    "#create a SparkContext and a SQLContext to use\n",
    "conf = SparkConf()\n",
    "conf.setMaster(\"spark://sparklab-master:7077\")\n",
    "conf.setAppName(\"Spark Classification with Naive Bayes - Iris Datasets\")\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "sqlContext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_file = \"/home/twster/Spark/Projects/datasets/iris2.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use csv format datasets and load the dataset with sqlCOntext format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+-------+\n",
      "|SepalLength|SepalWidth|PetalLength|PetalWidth|Species|\n",
      "+-----------+----------+-----------+----------+-------+\n",
      "|        5.1|       3.5|        1.4|       0.2| setosa|\n",
      "|        4.9|       3.0|        1.4|       0.2| setosa|\n",
      "|        4.7|       3.2|        1.3|       0.2| setosa|\n",
      "|        4.6|       3.1|        1.5|       0.2| setosa|\n",
      "|        5.0|       3.6|        1.4|       0.2| setosa|\n",
      "|        5.4|       3.9|        1.7|       0.4| setosa|\n",
      "|        4.6|       3.4|        1.4|       0.3| setosa|\n",
      "|        5.0|       3.4|        1.5|       0.2| setosa|\n",
      "|        4.4|       2.9|        1.4|       0.2| setosa|\n",
      "|        4.9|       3.1|        1.5|       0.1| setosa|\n",
      "|        5.4|       3.7|        1.5|       0.2| setosa|\n",
      "|        4.8|       3.4|        1.6|       0.2| setosa|\n",
      "|        4.8|       3.0|        1.4|       0.1| setosa|\n",
      "|        4.3|       3.0|        1.1|       0.1| setosa|\n",
      "|        5.8|       4.0|        1.2|       0.2| setosa|\n",
      "|        5.7|       4.4|        1.5|       0.4| setosa|\n",
      "|        5.4|       3.9|        1.3|       0.4| setosa|\n",
      "|        5.1|       3.5|        1.4|       0.3| setosa|\n",
      "|        5.7|       3.8|        1.7|       0.3| setosa|\n",
      "|        5.1|       3.8|        1.5|       0.3| setosa|\n",
      "+-----------+----------+-----------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create a dataframe\n",
    "#stored in a MYSQL database\n",
    "data = sqlContext.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(data_file)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert target into numerical categories\n",
    "labelIndexer = StringIndexer(inputCol=\"Species\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split row and just show SepalLength and Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n",
      "|SepalLength|Species|\n",
      "+-----------+-------+\n",
      "|        5.1| setosa|\n",
      "|        4.9| setosa|\n",
      "|        4.7| setosa|\n",
      "|        4.6| setosa|\n",
      "|        5.0| setosa|\n",
      "|        5.4| setosa|\n",
      "|        4.6| setosa|\n",
      "|        5.0| setosa|\n",
      "|        4.4| setosa|\n",
      "|        4.9| setosa|\n",
      "|        5.4| setosa|\n",
      "|        4.8| setosa|\n",
      "|        4.8| setosa|\n",
      "|        4.3| setosa|\n",
      "|        5.8| setosa|\n",
      "|        5.7| setosa|\n",
      "|        5.4| setosa|\n",
      "|        5.1| setosa|\n",
      "|        5.7| setosa|\n",
      "|        5.1| setosa|\n",
      "+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(\"SepalLength\",\"Species\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(SepalLength=5.1, SepalWidth=3.5, PetalLength=1.4, PetalWidth=0.2, Species=u'setosa')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take raw data from iris2 dataset.\n",
    "data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train the model\n",
    "#Split the data into train and test\n",
    "# To proceed, we will first randomly split the dataset into training set (70%) and test set (30%).\n",
    "trainData, testData = data.randomSplit([0.7, 0.3], seed = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+-------+\n",
      "|SepalLength|SepalWidth|PetalLength|PetalWidth|Species|\n",
      "+-----------+----------+-----------+----------+-------+\n",
      "|        4.3|       3.0|        1.1|       0.1| setosa|\n",
      "|        4.4|       2.9|        1.4|       0.2| setosa|\n",
      "|        4.4|       3.0|        1.3|       0.2| setosa|\n",
      "|        4.4|       3.2|        1.3|       0.2| setosa|\n",
      "|        4.6|       3.1|        1.5|       0.2| setosa|\n",
      "|        4.6|       3.2|        1.4|       0.2| setosa|\n",
      "|        4.7|       3.2|        1.6|       0.2| setosa|\n",
      "|        4.8|       3.0|        1.4|       0.1| setosa|\n",
      "|        4.8|       3.0|        1.4|       0.3| setosa|\n",
      "|        4.8|       3.1|        1.6|       0.2| setosa|\n",
      "+-----------+----------+-----------+----------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainData.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+-------+\n",
      "|SepalLength|SepalWidth|PetalLength|PetalWidth|Species|\n",
      "+-----------+----------+-----------+----------+-------+\n",
      "|        4.5|       2.3|        1.3|       0.3| setosa|\n",
      "|        4.6|       3.4|        1.4|       0.3| setosa|\n",
      "|        4.6|       3.6|        1.0|       0.2| setosa|\n",
      "|        4.7|       3.2|        1.3|       0.2| setosa|\n",
      "|        4.8|       3.4|        1.9|       0.2| setosa|\n",
      "|        4.9|       3.0|        1.4|       0.2| setosa|\n",
      "|        4.9|       3.1|        1.5|       0.1| setosa|\n",
      "|        4.9|       3.6|        1.4|       0.1| setosa|\n",
      "|        5.0|       3.2|        1.2|       0.2| setosa|\n",
      "|        5.0|       3.3|        1.4|       0.2| setosa|\n",
      "+-----------+----------+-----------+----------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testData.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting Training Data : 103\n"
     ]
    }
   ],
   "source": [
    "print(\"Counting Training Data : {}\".format(trainData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting Test Data : 47\n"
     ]
    }
   ],
   "source": [
    "print(\"Counting Test Data : {}\".format(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vecAssembler = VectorAssembler(inputCols=[\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train a NaiveBayes Model\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "\n",
    "#chain LabelIndexer, vecAssembler and NBmodel in a\n",
    "pipeline = Pipeline(stages=[labelIndexer, vecAssembler, nb])\n",
    "\n",
    "#Run stages in pipeline and train model\n",
    "model = pipeline.fit(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show the predictions\n",
      "+-----+----------+--------------------+\n",
      "|label|prediction|         probability|\n",
      "+-----+----------+--------------------+\n",
      "|  2.0|       2.0|[0.29698237383357...|\n",
      "|  2.0|       2.0|[0.21798511589122...|\n",
      "|  2.0|       2.0|[0.15141773405828...|\n",
      "|  2.0|       2.0|[0.20436085847774...|\n",
      "|  2.0|       2.0|[0.24788699074567...|\n",
      "|  2.0|       2.0|[0.22533897917645...|\n",
      "|  2.0|       2.0|[0.21072257132948...|\n",
      "|  2.0|       2.0|[0.16530848479213...|\n",
      "|  2.0|       2.0|[0.18841991732741...|\n",
      "|  2.0|       2.0|[0.20023264276145...|\n",
      "|  2.0|       2.0|[0.28149718404605...|\n",
      "|  2.0|       2.0|[0.20037174080684...|\n",
      "|  2.0|       2.0|[0.18351954523753...|\n",
      "|  2.0|       2.0|[0.24433103432406...|\n",
      "|  2.0|       2.0|[0.18864884421606...|\n",
      "|  2.0|       2.0|[0.17451529522505...|\n",
      "|  2.0|       2.0|[0.17250580082906...|\n",
      "|  0.0|       0.0|[0.49917720827077...|\n",
      "|  2.0|       2.0|[0.16640704731458...|\n",
      "|  0.0|       0.0|[0.50561466273043...|\n",
      "+-----+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on testData so we can measure the accuracy of our model on new data\n",
    "predictions = model.transform(testData)\n",
    "print(\"Show the predictions\")\n",
    "predictions.select(\"label\",\"prediction\",\"probability\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accurary : 0.936170212766\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", \n",
    "                                              predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print \"Model Accurary : {}\".format(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'metricName: metric name in evaluation (f1|weightedPrecision|weightedRecall|accuracy) (default: f1, current: accuracy)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.explainParam(\"metricName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseMatrix([[ 13.,   0.,   0.],\n",
      "             [  3.,  12.,   0.],\n",
      "             [  0.,   0.,  19.]])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "# Create (prediction, label) pairs\n",
    "predictionAndLabel = predictions.select(\"prediction\", \"label\").rdd\n",
    "\n",
    "# Generate confusion matrix\n",
    "metrics = MulticlassMetrics(predictionAndLabel)\n",
    "print metrics.confusionMatrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with Various Smoothing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Create ParamGrid and Evaluator for Cross Validation\n",
    "paramGrid = ParamGridBuilder().addGrid(nb.smoothing, [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]).build()\n",
    "cvEvaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run Cross-validation\n",
    "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=cvEvaluator)\n",
    "cvModel = cv.fit(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions on testData. cvModel uses the bestModel.\n",
    "cvPredictions = cvModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+\n",
      "|label|prediction|         probability|\n",
      "+-----+----------+--------------------+\n",
      "|  2.0|       2.0|[0.30030694251837...|\n",
      "|  2.0|       2.0|[0.22025422958423...|\n",
      "|  2.0|       2.0|[0.15149173803482...|\n",
      "|  2.0|       2.0|[0.20518906865455...|\n",
      "|  2.0|       2.0|[0.24956972908126...|\n",
      "|  2.0|       2.0|[0.22644817576129...|\n",
      "|  2.0|       2.0|[0.21050751177550...|\n",
      "|  2.0|       2.0|[0.16461564455715...|\n",
      "|  2.0|       2.0|[0.18893524268040...|\n",
      "|  2.0|       2.0|[0.20098739805581...|\n",
      "|  2.0|       2.0|[0.28730389628984...|\n",
      "|  2.0|       2.0|[0.20115179465289...|\n",
      "|  2.0|       2.0|[0.18403835547291...|\n",
      "|  2.0|       2.0|[0.24841050465935...|\n",
      "|  2.0|       2.0|[0.18921187643046...|\n",
      "|  2.0|       2.0|[0.17492305771120...|\n",
      "|  2.0|       2.0|[0.17286890844186...|\n",
      "|  0.0|       0.0|[0.50177370035199...|\n",
      "|  2.0|       2.0|[0.16659681368935...|\n",
      "|  0.0|       0.0|[0.50958191840212...|\n",
      "+-----+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select results to view\n",
    "cvPredictions.select(\"label\", \"prediction\", \"probability\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9574468085106383"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate bestModel found from Cross Validation\n",
    "evaluator.evaluate(cvPredictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
